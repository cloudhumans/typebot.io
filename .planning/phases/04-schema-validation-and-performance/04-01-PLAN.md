---
phase: 04-schema-validation-and-performance
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/lib/schema.validation.test.ts
autonomous: true
requirements: [VAL-01, VAL-02]

must_haves:
  truths:
    - "A Vitest test captures stdout from all 5 log message types and asserts field presence, nesting depth, and value types against the DD pipeline schema fixture"
    - "A benchmark test confirms 20 sequential logger.info calls complete in under 50ms total wall-clock time"
    - "All existing 15 tests plus the new schema/benchmark tests pass together"
  artifacts:
    - path: "packages/lib/schema.validation.test.ts"
      provides: "DD pipeline schema fixture test and performance benchmark"
      min_lines: 80
  key_links:
    - from: "packages/lib/schema.validation.test.ts"
      to: "packages/lib/logger.ts"
      via: "runLoggerScript child-process tsx pattern"
      pattern: "execSync.*tsx.*logger"
---

<objective>
Create the consolidated DD pipeline schema fixture test and performance benchmark for all instrumented log paths.

Purpose: VAL-01 ensures every log path emits JSON matching the DD pipeline contract (field presence, nesting depth, value types). VAL-02 confirms logging adds no measurable latency to workflow execution.
Output: packages/lib/schema.validation.test.ts with schema fixture assertions for all 5 message types and a performance benchmark.
</objective>

<execution_context>
@/home/giordanowt/.claude/get-shit-done/workflows/execute-plan.md
@/home/giordanowt/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-schema-validation-and-performance/04-RESEARCH.md
@.planning/phases/03-http-block-enrichment/03-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DD pipeline schema fixture test (VAL-01)</name>
  <files>packages/lib/schema.validation.test.ts</files>
  <action>
Create `packages/lib/schema.validation.test.ts` using the established `runLoggerScript` child-process + tsx pattern from `packages/lib/logger.test.ts`.

1. Copy the `runLoggerScript` helper and `tsxBin` resolution from `packages/lib/logger.test.ts` verbatim (same `path.resolve(__dirname, '../..')` for projectRoot, same pnpm tsx binary path).

2. Define the DD pipeline schema fixture as a plain TypeScript object at the top of the file:
   - `topLevel`: `['message', 'level', 'timestamp', 'ddsource', 'service']`
   - `ddsource`: `'nodejs'`
   - `service`: `'typebot-runner'`
   - `workflowFields`: `{ id: 'string', version: 'string', execution_id: 'string' }`
   - `typebotBlockFields`: `{ id: 'string', type: 'string' }`
   - `httpSuccessFields`: `{ url: 'string', method: 'string', status_code: 'number', duration: 'number' }`
   - `httpTimeoutFields`: `{ url: 'string', method: 'string', timeout_ms: 'number', duration: 'number' }`

3. Write 5 test cases inside `describe('DD Pipeline Schema Fixture (VAL-01)')`:
   a. `"Block Executed"` — logger.info, assert all top-level fields present, ddsource='nodejs', service='typebot-runner', workflow is object (not string) with id/version/execution_id all string, typebot_block is object with id/type both string
   b. `"HTTP Request Executed"` — logger.info, assert http is object with url(string), method(string), status_code(number), duration(number)
   c. `"HTTP Request Error"` — logger.warn, assert level='warn', http object with status_code(number)
   d. `"HTTP Request Timeout"` — logger.error, assert level='error', http object with timeout_ms(number), assert http.status_code is undefined (no synthetic 408)
   e. `"HTTP Request Failed"` — logger.error, assert level='error', error field is string (not Error object)

Use explicit `typeof` assertions for value types (not `toMatchObject` which only checks presence). Assert nesting depth by checking `typeof result.workflow === 'object'` and `result.workflow !== null`.

IMPORTANT: Do NOT import logger directly in the test file. Always use the `runLoggerScript` child-process pattern to avoid Winston singleton state leaking between tests.
  </action>
  <verify>
    <automated>cd /home/giordanowt/Repositories/typebot.io && npx vitest run packages/lib/schema.validation.test.ts 2>&1 | tail -20</automated>
  </verify>
  <done>5 schema fixture tests pass, asserting field presence, nesting depth, and value types for all 5 log message types against the DD pipeline contract</done>
</task>

<task type="auto">
  <name>Task 2: Add performance benchmark test (VAL-02)</name>
  <files>packages/lib/schema.validation.test.ts</files>
  <action>
Add a second `describe('Performance Benchmark (VAL-02)')` block to the same `schema.validation.test.ts` file.

Write one test: `'20 logger.info calls with block payloads complete in < 50ms total'`

Implementation:
1. Use `spawnSync` (not `execSync`) to separate stdout (JSON logs) from stderr (timing).
2. Build inline script string (do NOT pass payload via process.argv -- hardcode it inline to avoid tsx -e argv ambiguity per RESEARCH open question 2):
   ```
   const logger = require('./packages/lib/logger').default;
   const { performance } = require('perf_hooks');
   const payload = { workflow: { id: 'wf-bench', version: '2', execution_id: 'sess-bench' }, typebot_block: { id: 'b-bench', type: 'webhook' } };
   const t0 = performance.now();
   for (let i = 0; i < 20; i++) logger.info('Block Executed', payload);
   const elapsed = performance.now() - t0;
   process.stderr.write('ELAPSED:' + elapsed.toFixed(3));
   ```
3. Run via `spawnSync(tsxBin, ['-e', script], { cwd: projectRoot, env: { ...process.env, DD_LOGS_ENABLED: 'true', NODE_ENV: 'production' }, encoding: 'utf8' })`
4. Parse timing from `result.stderr` using regex `/ELAPSED:(\d+\.\d+)/`
5. Assert `elapsedMs < 50` (generous upper bound; expected < 5ms for synchronous Console transport)

CRITICAL: Write timing to `process.stderr.write()` directly, NOT `console.log` or `console.error`. logger.ts redirects console methods to Winston (lines 51-55), so console.log would emit JSON to stdout instead of the timing value.
  </action>
  <verify>
    <automated>cd /home/giordanowt/Repositories/typebot.io && npx vitest run packages/lib/schema.validation.test.ts 2>&1 | tail -20</automated>
  </verify>
  <done>All 6 tests in schema.validation.test.ts pass (5 schema + 1 benchmark). Benchmark confirms 20 logger calls complete well under 50ms threshold.</done>
</task>

</tasks>

<verification>
Run the full packages/lib test suite to confirm no regressions:
```bash
cd /home/giordanowt/Repositories/typebot.io && npx vitest run packages/lib/ 2>&1 | tail -30
```
Expected: All tests pass (15 existing + 6 new = 21 total).
</verification>

<success_criteria>
- schema.validation.test.ts exists with 6 passing tests
- VAL-01: All 5 log message types validated against DD pipeline schema fixture (field presence, nesting depth, value types)
- VAL-02: 20-block benchmark confirms < 50ms total (no p99 latency regression)
- All 21 tests across packages/lib/ pass
</success_criteria>

<output>
After completion, create `.planning/phases/04-schema-validation-and-performance/04-01-SUMMARY.md`
</output>
